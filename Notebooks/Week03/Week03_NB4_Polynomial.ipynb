{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5cacc2ee-c610-481d-8536-2d0b21fdc118",
      "metadata": {},
      "source": "## Polynomial regression"
    },
    {
      "cell_type": "markdown",
      "id": "04bfa1b8-7c3a-4fdc-bb21-a42ef07591e0",
      "metadata": {},
      "source": "We are going to look at data with a relationship between feature and target that is more complicated than linear:\n\n$$ y(x) = 4 + 2x - x^2 + 0.075x^3 $$\n\nCan we use \"linear regression\"?\n\nYes! -> Use ($x^0$, $x^1$, $x^2$, ....) as features"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9e76607-f120-4042-a392-ef6380f57bc8",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import numpy as np\nimport matplotlib.pyplot as plt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87be26f7-dce8-440e-941d-a9c898d4da36",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "noise = np.random.normal(0,1.5,30)\n\nx = np.linspace(0, 10, 30)\n\ny_underlying = 4 + 2*x - x**2 + 0.075*x**3 \ny = 4 + 2*x - x**2 + 0.075*x**3 + noise"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a13fe04-d510-484d-ae23-15d61cbd52f6",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# plot our theory curve\nplt.plot(x,y_underlying,'k')\n\n# plot our data generated from the theory curve + noise\nplt.scatter(x,y,color='k',marker='o')\n\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "e4ebdd56-c190-4bbe-961e-f300e871cd4f",
      "metadata": {},
      "source": "## ML training process\n\n* get the data and pre-process if needed\n* choose the model\n* train the model\n* evaluate the model"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf78980b-fc3a-4427-af04-3040e35e59a0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Prepare the data if needed\n\n# np.c_ makes a 2D array with columns out of the included elements\nx_higherorder = np.c_[x**1, x**2, x**3]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e46e396d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_higherorder"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fd8d8d2-0cf2-4e17-a1d0-35c163f9f77a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Choose the model\n\nimport sklearn.linear_model\nmodel = sklearn.linear_model.LinearRegression()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bdf578f-723a-4c3e-b84d-bc2c421a9fc2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Train the model\n\nmodel.fit(x_higherorder,\n          y)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad7de41-4f31-4984-baa5-9b1339c9ab0e",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Evaluate the model\n\ny_pred = model.predict(x_higherorder)\n\n# plot our theory curve\nplt.plot(x,y_underlying,'k')\n\n# plot our data generated from the theory curve + noise\nplt.scatter(x,y,color='black')\n\n# plot the trained model\nx_model_vals = np.linspace(0, 10, 50)\nx_model_higherorder = np.c_[x_model_vals**1, x_model_vals**2, x_model_vals**3]\ny_model_vals = model.predict(x_model_higherorder)\nplt.plot(x_model_vals,y_model_vals,'blue')\n\nplt.show()\n\n# print the model\nprint('Intercept = ', model.intercept_)\nprint('Model coefficients = ', model.coef_)\nprint('Compare to y(x) = 4+2x-x^2+0.075x^3')\n\n# print the MSE of the predictions relative to \n# the true y values of the test data\nfrom sklearn.metrics import mean_squared_error\nprint('MSE = ', mean_squared_error(y, y_pred))"
    },
    {
      "cell_type": "markdown",
      "id": "f92d86de-7a96-4d37-8728-0c4c70214efd",
      "metadata": {},
      "source": "## The scikit-learn way\n\nScikit-Learn has a natural way of doing this: PolynomialFeatures.\n\nThe result is the same as what's shown above, it simply requires doing a \"fit_transform\" on the feature data (here our x variable)."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "912549df-9927-4eb6-a7bd-02f615db2697",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Prepare the data if needed\n\n# The sklearn way of make polynomial features\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly = PolynomialFeatures(degree=3, include_bias=False)\nx_poly = poly.fit_transform(x.reshape(-1, 1))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c38a29",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_poly"
    },
    {
      "cell_type": "markdown",
      "id": "0cfb5649-b7e5-4c1c-aa1d-ad0e48700b0a",
      "metadata": {},
      "source": "Technical note:\n* Above and here, we might normally think that we want to include the bias term (after all, we included 1's when doing the exact solution and SGD before!)  In practice, when you use PolynomialFeatures together with sklearn.linear_model.LinearRegression, the latter takes care by default of adding a column of 1's (LinearRegression sets the fit_intercept parameter to True by default), so you don't need to add it as well in PolynomialFeatures. Therefore, in PolynomialFeatures one usually keeps include_bias=False.\n* The situation is different if you use statsmodels.OLS instead of LinearRegression\n* credit goes to https://stackoverflow.com/questions/59725907/scikit-learn-polynomialfeatures-what-is-the-use-of-the-include-bias-option"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ca27dac-9fd2-47a2-bd6c-2407db631da9",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Choose the model\n\nimport sklearn.linear_model\nmodel = sklearn.linear_model.LinearRegression()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8847aba4-9382-4dee-ae88-d4847ac01c01",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Train the model\n    \nmodel.fit(x_poly, y)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6cdf7e9-ca7d-47be-9b05-6184d121af22",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Evaluate the model\n\ny_pred = model.predict(x_poly)\n\n# plot our theory curve\nplt.plot(x,y_underlying,'k')\n\n# plot our data generated from the theory curve + noise\nplt.scatter(x,y,color='black')\n\n# plot the trained model\nx_model_vals = np.linspace(0, 10, 50)\nx_model_higherorder = poly.fit_transform(x_model_vals.reshape(-1,1))\ny_model_vals = model.predict(x_model_higherorder)\nplt.plot(x_model_vals,y_model_vals,'blue')\n\nplt.show()\n\n# print the model\nprint('Intercept = ', model.intercept_)\nprint('Model coefficients = ', model.coef_)\nprint('Compare to y(x) = 4+2x-x^2+0.075x^3')\n\n# print the MSE of the predictions relative to \n# the true y values of the test data\nfrom sklearn.metrics import mean_squared_error\nprint('MSE = ', mean_squared_error(y, y_pred))"
    },
    {
      "cell_type": "markdown",
      "id": "edb003f5-d4b1-4768-92d6-e2d07cdd9968",
      "metadata": {},
      "source": "Note that this is just like above!\n\nAnd it should be as long as we don't include any random variation here in data chosen between the two different cases."
    },
    {
      "cell_type": "markdown",
      "id": "d5073a4f-c2ea-4588-a930-be754ac94965",
      "metadata": {},
      "source": "## Illustration of different orders of polynomials"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4819695-a78d-47c2-8562-d8108bc4bce7",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "def train_higher_order(o = 1):\n\n    model = sklearn.linear_model.LinearRegression()\n    \n    poly = PolynomialFeatures(degree=o, include_bias=False)\n    x_poly = poly.fit_transform(x.reshape(-1, 1))\n    \n    model.fit(x_poly, y)\n    \n    y_pred = model.predict(x_poly)\n    \n    plt.plot(x,y_underlying,'k')\n    \n    plt.scatter(x,y,color='k',marker='o')\n    \n    x_learned = np.linspace(0,10,1000)\n    x_learned_poly = poly.transform(x_learned.reshape(-1, 1))\n    y_learned = model.predict(x_learned_poly)\n    plt.plot(x_learned,y_learned,'b')\n    \n    plt.show()\n    \n    print('MSE = ', mean_squared_error(y, y_pred))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "886e96fb-6556-44af-9942-7449d5cb375e",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "train_higher_order(2)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65788d3b-3ca8-418b-b825-4389a1bfa209",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import ipywidgets"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "568e5cbe-9f27-4d5a-993e-c7c53d53faf5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "ipywidgets.interactive(train_higher_order,o=(1,25))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b1728e3-697c-4ba5-a891-477b6f907065",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.preprocessing import StandardScaler"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "423a5554-10b7-49f6-a80d-43e7e2b18bb0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "scaler = StandardScaler()\nx = scaler.fit_transform(x.reshape(-1,1))    "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d6b4e9",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7495dbb-0821-43ed-ace0-fb87fd4b257f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "def train_higher_order(o = 1):\n\n    model = sklearn.linear_model.LinearRegression()\n    \n    poly = PolynomialFeatures(degree=o, include_bias=False)\n    x_poly = poly.fit_transform(x)\n    \n    model.fit(x_poly, y)\n    \n    y_pred = model.predict(x_poly)\n    \n    plt.plot(x,y_underlying,'k')\n    \n    plt.scatter(x,y,color='k',marker='o')\n    \n    x_learned = np.linspace(-2,2,1000)\n    x_learned_poly = poly.transform(x_learned.reshape(-1, 1))\n    y_learned = model.predict(x_learned_poly)\n    plt.plot(x_learned,y_learned,'b')\n    plt.ylim([-7,7])\n    plt.show()\n    \n    print('MSE = ', mean_squared_error(y, y_pred))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c1e90be-1a10-4271-bf50-485b8fa2dad3",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "train_higher_order(3)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aabaa27e-936a-443b-887e-3b7134a6d1c0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import ipywidgets"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d921a04-acd1-4eb6-a545-5e2b65137d60",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "ipywidgets.interactive(train_higher_order,o=(1,25))"
    },
    {
      "cell_type": "markdown",
      "id": "a7f0414e",
      "metadata": {},
      "source": "## Regularization"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2d5588",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4faf1596",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "def train_higher_order(o = 1, model = sklearn.linear_model.LinearRegression()):\n\n    poly = PolynomialFeatures(degree=o, include_bias=False)\n    x_poly = poly.fit_transform(x)\n    \n    model.fit(x_poly, y)\n    \n    y_pred = model.predict(x_poly)\n    \n    plt.plot(x,y_underlying,'k')\n    \n    plt.scatter(x,y,color='k',marker='o')\n    \n    x_learned = np.linspace(-2,2,1000)\n    x_learned_poly = poly.transform(x_learned.reshape(-1, 1))\n    y_learned = model.predict(x_learned_poly)\n    plt.plot(x_learned,y_learned,'b')\n    plt.ylim([-7,7])\n    plt.show()\n    \n    print('MSE = ', mean_squared_error(y, y_pred))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72f52668",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "train_higher_order(o=20, model=sklearn.linear_model.LinearRegression())"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d164ab",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "ipywidgets.interactive(train_higher_order,\n                       o=(1,25),\n                       model=[sklearn.linear_model.LinearRegression(),\n                              Ridge(alpha=1, solver=\"cholesky\", random_state=42),\n                              Lasso(alpha=1, random_state=42),\n                              ElasticNet(alpha=1, l1_ratio=0.5, random_state=42)])"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}